{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import math\n",
    "import toad\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED\n",
    "import matplotlib.pyplot as plt\n",
    "from toad.metrics import KS, AUC\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def load_pickle(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def save_pickle(obj, file):\n",
    "    with open(file, \"wb\") as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import Linear, HeteroConv, GraphConv, GAT, RGCNConv, BatchNorm, GCN\n",
    "from torch_geometric.nn.models import JumpingKnowledge\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "pseudo_ratio = 0.4\n",
    "num_epoches = 13\n",
    "seed_everything(seed=3407)\n",
    "pd.set_option('display.max_rows', 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "pseudo_ratio = 0.4\n",
    "num_epoches = 6\n",
    "seed_everything(seed=3407)\n",
    "pd.set_option('display.max_rows', 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(file, f, pseudo=0):\n",
    "    if f.endswith(\".pkl\"):\n",
    "        data, metadata = load_pickle(f\"data/{file}/{f}\")\n",
    "        data = pd.DataFrame(data, columns=['volt','current','soc','max_single_volt','min_single_volt','max_temp','min_temp','timestamp'])\n",
    "        # data[\"pwoer\"] = data[\"volt\"] * (-data[\"current\"])\n",
    "        \n",
    "        # 一致性\n",
    "        # data[\"consistency\"] = data[\"volt\"].std() * 0.2286 + data[\"soc\"].std() * 0.3699 + (data.max_temp - data.min_temp).std() * 0.1242 + (data[\"volt\"] / (-data[\"current\"])).std() * 0.1774 #  + (data[\"current\"] * data[\"timestamp\"].diff().fillna(0) / data[\"soc\"].diff().fillna(0)).std() * 0.0999\n",
    "\n",
    "        # 热风险分析算法\n",
    "        # data[\"single_volt_range\"] = data.max_single_volt - data.min_single_volt\n",
    "        # data[\"single_volt_range_diff\"] = data[\"single_volt_range\"].diff().fillna(0)\n",
    "        # data[\"temp_range\"] = data.max_temp - data.min_temp\n",
    "\n",
    "        data[\"mileage\"] = metadata.get(\"mileage\")\n",
    "        if metadata.get(\"label\"):\n",
    "            data[\"label\"] = 1 if metadata.get(\"label\") == \"10\" else 0\n",
    "        else:\n",
    "            data[\"label\"] = pseudo\n",
    "        \n",
    "        data[\"file_name\"] = f\n",
    "        return data #.drop(columns=['max_single_volt','min_single_volt','max_temp','min_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [read_pickle(\"Train\", f) for f in tqdm(os.listdir(\"data/Train/\"), desc=\"load train :::\")]\n",
    "test = [read_pickle(\"Test_A\", f) for f in tqdm(os.listdir(\"data/Test_A/\"), desc=\"load  test :::\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = [data[\"file_name\"][0] for data in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_index = int(sum([d[\"label\"][0] for d in train]) / len(train) * pseudo_ratio * len(test))\n",
    "good_index = int((len(train) - sum([d[\"label\"][0] for d in train])) / len(train) * pseudo_ratio * len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score = pd.read_csv(\"result.csv\").sort_values(\"score\").reset_index(drop=True)\n",
    "good_filename = pred_score[\"file_name\"].tolist()[:good_index]\n",
    "bad_filename = pred_score[\"file_name\"].tolist()[-bad_index:]\n",
    "pseudo = [read_pickle(\"Test_A\", f, pseudo=1) for f in tqdm(bad_filename, desc=\"load pseudo  bad :::\")] \\\n",
    "    # + [read_pickle(\"Test_A\", f, pseudo=0) for f in tqdm(good_filename, desc=\"load pseudo good :::\")]\n",
    "train.extend(pseudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(full_list, ratio, shuffle=False):\n",
    "    n_total = len(full_list)\n",
    "    offset = int(n_total * ratio)\n",
    "\n",
    "    if n_total == 0 or offset < 1:\n",
    "        return [], full_list\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(full_list)\n",
    "\n",
    "    sublist_1 = full_list[:offset]\n",
    "    sublist_2 = full_list[offset:]\n",
    "    \n",
    "    return sublist_1, sublist_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = []\n",
    "target = []\n",
    "for i in range(1, 2):\n",
    "    source.extend([i for i in range(256 - i)])\n",
    "    target.extend([i for i in range(i, 256)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_graph(datasets, mode=\"train\"):\n",
    "    # rations = set()\n",
    "    graphs = []\n",
    "    for row_data in tqdm(datasets, desc=f\"process {mode} graph :::\"):\n",
    "        data = row_data.copy()\n",
    "        # rations.update(data[\"timestamp\"].diff().fillna(0).astype(int).unique())\n",
    "        data[\"timestamp\"] = (data[\"timestamp\"] - data[\"timestamp\"].min()).astype(int)\n",
    "        data[\"timestamp_diff\"] = data[\"timestamp\"].diff().fillna(0).apply(lambda x: math.log(x+1, 60))\n",
    "        x = torch.FloatTensor(data.drop(columns=[col for col in [\"file_name\", \"label\"] if col in data.columns]).values.tolist())\n",
    "        edge_index = torch.LongTensor([source, target]) # ([[i for i in range(255)], [i + 1 for i in range(255)]])\n",
    "        edge_weight = data[\"timestamp\"].loc[target].values - data[\"timestamp\"].loc[source].values\n",
    "        edge_attr = torch.FloatTensor(edge_weight)\n",
    "        # edge_attr = torch.FloatTensor(data[\"timestamp\"].diff().fillna(0).apply(lambda x: math.log(x+1, 60)).tolist()[1:])\n",
    "\n",
    "        if mode != \"test\":\n",
    "            # 对正向样本进行采样扩充数据\n",
    "            y = torch.LongTensor([data[\"label\"][0]])\n",
    "            \n",
    "            # if data[\"label\"][0] == 1:\n",
    "            #     for i in range(1):\n",
    "            #         _data = row_data.sample(frac=0.95).sort_index().reset_index(drop=True)\n",
    "            #         _data = pd.concat([row_data[:6], _data, row_data[-(len(row_data) - len(_data) - 6):]]).reset_index(drop=True)\n",
    "            #         _data[\"timestamp\"] = (_data[\"timestamp\"] - _data[\"timestamp\"].min()).astype(int)\n",
    "            #         _data[\"timestamp_diff\"] = _data[\"timestamp\"].diff().fillna(0).apply(lambda x: math.log(x+1, 60) if x > 0 else 0)\n",
    "            #         _x = torch.FloatTensor(_data.drop(columns=[col for col in [\"file_name\", \"label\"] if col in _data.columns]).values.tolist())\n",
    "            #         _edge_index = torch.LongTensor([[i for i in range(len(_data))], [i + 1 for i in range(len(_data))]])\n",
    "            #         _edge_attr = torch.FloatTensor(_data[\"timestamp\"].diff().fillna(0).apply(lambda x: math.log(x+1, 60) if x > 0 else 0).tolist()[1:])\n",
    "            #         _grpha = Data(x=_x, edge_index=_edge_index, edge_attr=_edge_attr, y=y)\n",
    "            #         graphs.append(_grpha)\n",
    "\n",
    "            grpha = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        else:\n",
    "            grpha = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "            \n",
    "        graphs.append(grpha)\n",
    "    # print(rations, len(rations))\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_train = process_graph(train, mode=\"train\")\n",
    "graph_test = process_graph(test, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_trin, graph_vail = data_split(graph_train, ratio=0.7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphaDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list):\n",
    "        super().__init__()\n",
    "        self.data, self.slices = self.collate(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateset_train = GraphaDataset(graph_train)\n",
    "dateset_trin = GraphaDataset(graph_trin)\n",
    "dateset_vail = GraphaDataset(graph_vail)\n",
    "dateset_test = GraphaDataset(graph_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(dateset_train, batch_size=batch_size, shuffle=True)\n",
    "loader_trin = DataLoader(dateset_trin, batch_size=batch_size, shuffle=True)\n",
    "loader_vail = DataLoader(dateset_vail, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(dateset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNTest(torch.nn.Module):\n",
    "    def __init__(self, dataset, num_layers, hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden)\n",
    "        self.bn1 = BatchNorm(hidden)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for i in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden, hidden))\n",
    "        # self.lin1 = Linear(hidden, hidden)\n",
    "        self.lin2 = Linear(hidden, dataset.num_classes)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.bn1.reset_parameters()\n",
    "        self.conv1.reset_parameters()\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        # self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if self.training:\n",
    "            x = self.add_noise(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        # x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_noise(x, perturb_noise=0.05):\n",
    "        perturb = torch.empty_like(x).uniform_(-perturb_noise, perturb_noise)\n",
    "        return x + perturb\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = GCN(hidden_channels=128).to(device)\n",
    "model = GCNTest(dateset_train, 4, 256).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.025)\n",
    "t_total = (len(dateset_train) // batch_size + 1) * num_epoches\n",
    "# scheduler = get_default_cosine_schedule_with_warmup(optimizer, t_total, warmup_ratio=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, final_div_factor=1000, div_factor=10, max_lr=5e-4, total_steps=t_total, pct_start=0.4)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1, 2, 3], gamma=0.5)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor([0.4, 0.6]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    data_iter = tqdm(loader, desc=\"pyg model training :::\")\n",
    "\n",
    "    for data in data_iter:\n",
    "        data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        data_iter.set_postfix(loss='{:.4f}'.format(loss.cpu().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, epoch, mode=\"train\"):\n",
    "    model.eval()\n",
    "    preps = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader, desc=f\"pyg {mode} evaluate :::\"):\n",
    "            trues.extend(data.y.cpu().numpy().tolist())\n",
    "            data.to(device)\n",
    "            out = model(data)\n",
    "            pred = F.softmax(out)[:, 1]\n",
    "            preps.extend(pred.cpu().numpy().tolist())\n",
    "\n",
    "    return roc_auc_score(trues, preps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader):\n",
    "    model.eval()\n",
    "\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader, desc=\"pyg model inference :::\"):\n",
    "            data.to(device)\n",
    "            out = model(data)\n",
    "            results.extend(F.softmax(out)[:, 1].cpu().numpy().tolist())\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoches):\n",
    "    train(loader_train)\n",
    "    train_auc = test(loader_train, epoch, mode=\"train\")\n",
    "\n",
    "    if epoch >= 3:\n",
    "        pd.DataFrame(list(zip(test_index, inference(loader_test))), columns=[\"file_name\", \"score\"]).to_csv(f\"{epoch}_result.csv\", index=False)\n",
    "    \n",
    "    print(f'epoch: {epoch:03d}, train auc: {train_auc:.4f}')\n",
    "    \n",
    "    # count = 0\n",
    "    # if count == 0 and train_auc > 0.925:\n",
    "    #     scheduler.step()\n",
    "    #     count += 1\n",
    "\n",
    "#     # train(loader_trin)\n",
    "#     # train_auc = test(loader_trin, epoch, mode=\"train\")\n",
    "#     # test_auc = test(loader_vail, epoch, mode=\" vail\")\n",
    "#     # print(f'epoch: {epoch:03d}, train auc: {train_auc:.4f}, val auc: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epoches):\n",
    "#     # model.train()\n",
    "#     train(loader_trin)\n",
    "\n",
    "#     # model.eval()\n",
    "#     train_auc = test(loader_trin, epoch)\n",
    "#     test_auc = test(loader_vail, epoch)\n",
    "#     print(f'epoch: {epoch:03d}, train auc: {train_auc:.4f}, val auc: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = inference(loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(test_index, pred)), columns=[\"file_name\", \"score\"]).to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score = pd.DataFrame(\n",
    "    list(zip(test_index, pred)), columns=[\"file_name\", \"score\"]\n",
    ").sort_values(\"score\").reset_index(drop=True)\n",
    "pred_score = pd.read_csv(\"submit.csv\").sort_values(\"score\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_filename = pred_score[\"file_name\"].tolist()[:good_index]\n",
    "bad_filename = pred_score[\"file_name\"].tolist()[-bad_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91d8ac8ac98a00daee01b170ecc4de38a4b78e57473b1984dedfa9b67acb5aae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
